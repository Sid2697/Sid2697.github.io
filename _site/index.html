<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Siddhant Bansal - Home</title>
  <meta name="description" content="Siddhant Bansal">
  <link rel="stylesheet" href="http://localhost:4000/css/main.css">
  <link rel="canonical" href="http://localhost:4000/">
<link rel="shortcut icon" type ="image/x-icon" href="http://localhost:4000/images/favicon.ico">



</head>


  <body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container-fluid">
	<div class="navbar-header">
	  <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse-1" aria-expanded="false">
		<span class="sr-only">Toggle navigation</span>
		<span class="icon-bar"></span>
		<span class="icon-bar"></span>
		<span class="icon-bar"></span>
	  </button>

    <a class="navbar-brand" href="http://localhost:4000/">Siddhant Bansal</a>
	</div>
	<div class="collapse navbar-collapse" id="navbar-collapse-1">
	  <ul class="nav navbar-nav navbar-right">
		<li><a href="http://localhost:4000/">Home</a></li>
		<li><a href="http://localhost:4000/publications">Publications</a></li>
		<li><a href="http://localhost:4000/projects">Projects</a></li>
		<li><a href="http://localhost:4000/experience">Experience</a></li>
		<li><a href="https://sid2697.github.io/Blog_Sid">Blog</a></li>
	  </ul>
	</div>
  </div>
</div>


    <div class="container-fluid">
      <div class="row">
        <div id="gridid" class="col-sm-12">
  <div class="container-fluid">

  <div class="row">

    <div class="col-sm-8">

      <p>I am an MS by Research candidate at <a href="http://cvit.iiit.ac.in">CVIT, IIIT Hyderabad</a>. I work with <a href="https://faculty.iiit.ac.in/~jawahar/index.html">Prof. C.V. Jawahar</a> and <a href="https://www.cse.iitd.ac.in/~chetan/">Prof. Chetan Arora</a>.
My research interest lies in Computer Vision, Pattern Recognition, and Machine Learning. My graduate research focuses on devising learning-based methods for understanding and exploring various aspects of first-person (egocentric) vision. Earlier, I worked on improving word recognition and retrieval in large document collection under the guidance of <a href="https://faculty.iiit.ac.in/~jawahar/index.html">Prof. C.V. Jawahar</a>. Previously, I worked with <a href="https://people.iitgn.ac.in/~shanmuga/">Prof. Shanmuganathan Raman</a> on 3D Computer Vision.</p>

      <p>My ultimate goal is to contribute to the development of systems capable of understanding the world as we do. I’m an inquisitive person, and I’m always willing to learn about fields including, but not limited to, science, technology, astrophysics, and physics.</p>

      <p align="center">
  <a href="./docs/Siddhant_Bansal.pdf">CV</a> /
  <a href="https://scholar.google.com/citations?hl=en&amp;user=ciok5VwAAAAJ">Google Scholar</a> /
  <a href="https://github.com/Sid2697">Github</a> /
  <a href="https://www.linkedin.com/in/siddhant-bansal/">LinkedIn</a> /
  <a href="https://arxiv.org/a/bansal_s_1.html"> arXiv </a> /
  <a href="https://orcid.org/0000-0003-2636-0066">ORCID</a>
</p>

      <h3 id="news">News</h3>
      <hr />

      <p>March, 2022 :
<em><a href="https://ego4d-data.org/">Ego4D:</a> <a href="https://ego4d-data.org/">Around the World in 3,000 Hours of Egocentric Video</a> got accepted to <a href="https://cvpr2022.thecvf.com/">CVPR 2022</a>!</em></p>

      <p>Oct, 2021 :
<em>Introducing <a href="https://ego4d-data.org/">Ego4D:</a> A massive-scale egocentric video dataset along with five benchmarks. Glad to have been a part of the Hands and Object Benchmark team and data collection effort at <a href="https://www.iiit.ac.in">IIIT-Hyderabad</a>. <a href="https://arxiv.org/abs/2110.07058">[paper]</a> <a href="https://ego4d-data.org/">[project page]</a> <a href="https://www.youtube.com/watch?v=taC2ZKl9IsE">[video]</a> <a href="https://drive.google.com/file/d/1oknfQIH9w1rXy6I1j5eUE6Cqh96UwZ4L/view">[benchmark’s description]</a><a href="https://eyewear-computing.org/EPIC_ICCV21/">[EPIC@ICCV2021 Reveal Session]</a></em></p>

      <p>Oct, 2020 :
<em><a href="https://arxiv.org/abs/2010.14411">Improving Word Recognition using Multiple Hypotheses and Deep Embeddings</a> got accepted to <a href="https://www.icpr2020.it">ICPR 2020</a>!</em></p>

      <p>July, 2020 :
<em>Submitted my latest work with <a href="https://kris314.github.io">Praveen Krishnan</a> and <a href="https://faculty.iiit.ac.in/~jawahar/index.html">Prof. C.V. Jawahar</a> to <a href="https://www.icpr2020.it">ICPR 2020</a>.</em></p>

      <p>April, 2020 :
<em><a href="https://sid2697.github.io/Word-recognition-and-retrieval/">Fused Text Recogniser and Deep Embeddings Improve Word Recognition and Retrieval </a>got accepted to DAS 2020!</em></p>

      <h4 id="see-all-news"><a href="http://localhost:4000/allnews.html">See all news</a></h4>

    </div>

    <div class="col-sm-4" style="display:table-cell; vertical-align:middle; text-align:left">

      <ul style="overflow: hidden">
  <img src="http://localhost:4000/images/profile_pic.jpeg" class="img-responsive" width="100%" />
  </ul>

      <p><!-- <br clear="all" /> --></p>

      <p><a href="mailto:siddhant.bansal@research.iiit.ac.in">siddhant.bansal@research.iiit.ac.in</a> <br />
  Center for Visual Information and Technology (<b>CVIT</b>), 
  International Institute of Information Technology (<b>IIIT</b>),
  Hyderabad, India.<br /></p>

    </div>

  </div>
</div>

<div class="col-sm-12">

  <h3 id="publications">Publications</h3>
  <hr />

  <div class="col-sm-11 clearfix">
    <div class="well">
      <pubtit>Ego4D: Around the World in 3,000 Hours of Egocentric Video</pubtit>

      <p><img src="http://localhost:4000/images/pubpic/ego4d.png" class="img-responsive" width="250px" style="float: left" /></p>

      <p>We offer 3,025 hours of daily-life activity video spanning hundreds of scenarios captured by 855 unique camera wearers from 74 worldwide locations and 9 different countries.<br />We present a host of new benchmark challenges centered around understanding the first-person visual experience in the past (querying an episodic memory), present (analyzing hand-object manipulation, audio-visual conversation, and social interactions), and future (forecasting activities).</p>

      <p><em><br />Kristen Grauman, Andrew Westbury, Eugene Byrne, Zachary Chavis, Antonino Furnari, Rohit Girdhar, Jackson Hamburger, Hao Jiang, Miao Liu, Xingyu Liu, Miguel Martin, Tushar Nagarajan, Ilija Radosavovic, Santhosh Kumar Ramakrishnan, Fiona Ryan, Jayant Sharma, Michael Wray, Mengmeng Xu, Eric Zhongcong Xu, Chen Zhao, <a href="https://sid2697.github.io/"><b>Siddhant Bansal</b></a>, Dhruv Batra, Vincent Cartillier, Sean Crane, Tien Do, Morrie Doulaty, Akshay Erapalli, Christoph Feichtenhofer, Adriano Fragomeni, Qichen Fu, Christian Fuegen, Abrham Gebreselasie, Cristina Gonzalez, James Hillis, Xuhua Huang, Yifei Huang, Wenqi Jia, Weslie Khoo, Jachym Kolar, Satwik Kottur, Anurag Kumar, Federico Landini, Chao Li, Yanghao Li, Zhenqiang Li, Karttikeya Mangalam, Raghava Modhugu, Jonathan Munro, Tullie Murrell, Takumi Nishiyasu, Will Price, Paola Ruiz Puentes, Merey Ramazanova, Leda Sari, Kiran Somasundaram, Audrey Southerland, Yusuke Sugano, Ruijie Tao, Minh Vo, Yuchen Wang, Xindi Wu, Takuma Yagi, Yunyi Zhu, Pablo Arbelaez, David Crandall, Dima Damen, Giovanni Maria Farinella, Bernard Ghanem, Vamsi Krishna Ithapu, C. V. Jawahar, Hanbyul Joo, Kris Kitani, Haizhou Li, Richard Newcombe, Aude Oliva, Hyun Soo Park, James M. Rehg, Yoichi Sato, Jianbo Shi, Mike Zheng Shou, Antonio Torralba, Lorenzo Torresani, Mingfei Yan, Jitendra Malik</em></p>

      <p>Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022</p>

      <p><a href="https://arxiv.org/abs/2110.07058">Paper</a>
 /
 <a href="https://ego4d-data.org/">Project Page</a>
 /
 <a href="https://www.youtube.com/watch?v=taC2ZKl9IsE">Video</a>
 /
 <a href="https://drive.google.com/file/d/1oknfQIH9w1rXy6I1j5eUE6Cqh96UwZ4L/view">Benchmark’s description</a>
 /
 <a href="https://eyewear-computing.org/EPIC_ICCV21/">EPIC@ICCV2021 Ego4D Reveal Session</a></p>

    </div>
  </div>

  <div class="col-sm-11 clearfix">
    <div class="well">
      <pubtit>Improving Word Recognition using Multiple Hypotheses and Deep Embeddings</pubtit>

      <p><img src="http://localhost:4000/images/pubpic/Confidence_module.png" class="img-responsive" width="250px" style="float: left" /></p>

      <p>We propose to fuse recognition-based and recognition-free approaches for word recognition using learning-based methods.</p>

      <p><em><b>Siddhant Bansal</b>, <a href="https://kris314.github.io"> Praveen Krishnan </a>, and <a href="https://faculty.iiit.ac.in/~jawahar/index.html"> C.V. Jawahar </a></em></p>

      <p>International Conference on Pattern Recognition (<b>ICPR</b>), 2020</p>

      <p><a href="https://arxiv.org/pdf/2010.14411.pdf">PDF</a>
 /
 <a href="https://sid2697.github.io/embednet_cab/">Project Page</a>
 /
 <a href="https://github.com/Sid2697/Word-recognition-EmbedNet-CAB">Code (GitHub)</a>
 /
 <a href="https://youtu.be/T_TYL-_HpbY">Video (YouTube)<br /><br /></a></p>

    </div>
  </div>

  <div class="col-sm-11 clearfix">
    <div class="well">
      <pubtit>Fused Text Recogniser and Deep  Embeddings Improve  Word  Recognition  and  Retrieval</pubtit>

      <p><img src="http://localhost:4000/images/pubpic/WordRecVisualisation_website.png" class="img-responsive" width="250px" style="float: left" /></p>

      <p>Fusing recognition-based and recognition-free approaches using rule-based methods for improving word recognition and retrieval. <span style="color:red;">(ORAL)</span></p>

      <p><em><b>Siddhant Bansal</b>, <a href="https://kris314.github.io"> Praveen Krishnan </a>, and <a href="https://faculty.iiit.ac.in/~jawahar/index.html"> C.V. Jawahar </a></em></p>

      <p>IAPR International Workshop on Document Analysis and System (<b>DAS</b>), 2020</p>

      <p><a href="https://arxiv.org/pdf/2007.00166.pdf">PDF</a>
 /
 <a href="../images/pubpic/Word_Retrieval_demo.gif">Demo</a>
 /
 <a href="https://sid2697.github.io/Word-recognition-and-retrieval/">Project Page</a>
 /
 <a href="https://github.com/Sid2697/Word-recognition-and-retrieval">Code (Github)</a>
 /
 <a href="../papers/Siddhant_Bansal_V4.pdf">Poster</a></p>

    </div>
  </div>

  <p><br clear="all" /></p>

  <h4 id="see-all-publications"><a href="http://localhost:4000/publications">See all publications</a></h4>

</div>

<div class="col-sm-12">

  <h3 id="service">Service</h3>
  <hr />
  <p><strong>Conference Reviewer</strong>: CVPR 2022, ECCV 2022</p>

  <p><strong>Workshop Reviewer</strong>: Joint 1st Ego4D and 10th EPIC Workshop (CVPR 2022)</p>
  <p>   </p>

  <h3 id="blog">Blog</h3>
  <hr />

  <h3 id="deep-future-gaze-gaze-anticipation-on-egocentric-videos-using-adversarial-networks">Deep Future Gaze: Gaze Anticipation on Egocentric Videos Using Adversarial Networks</h3>
  <p>This paper proposes a <em>Generative Adversarial Network</em> (GAN) based architecture called Deep Future Gaze (DFG) for addressing the task of <em>gaze anticipation</em> in egocentric videos.</p>
  <h4 id="link-to-the-article"><a href="https://sid2697.github.io/Blog_Sid/paper_summary/2020/09/01/Deep-future-gaze.html">Link</a> to the article!</h4>

  <h3 id="first-person-action-recognition-using-deep-learned-descriptors">First Person Action Recognition Using Deep Learned Descriptors</h3>
  <p>This paper proposes a three-stream convolutional neural network architecture for the task of action recognition in first-person videos.</p>
  <h4 id="link-to-the-article-1"><a href="https://sid2697.github.io/Blog_Sid/paper_summary/2020/08/19/action-descriptors-Suriya.html">Link</a> to the article!</h4>

  <h3 id="two-stream-convolutional-networks-for-action-recognition-in-videos">Two-Stream Convolutional Networks for Action Recognition in Videos</h3>
  <p>This paper proposes a two-stream convolutional neural network architecture for the task of action recognition in a video.</p>
  <h4 id="link-to-the-article-2"><a href="https://sid2697.github.io/Blog_Sid/paper_summary/2020/08/16/Two-Stream-Zisserman-nips2014.html">Link</a> to the article!</h4>

  <p>   </p>
  <h4 id="see-all-articles"><a href="https://sid2697.github.io/Blog_Sid">See all articles</a></h4>

  <p>   </p>

</div>

</div>

      </div>
    </div>

    <div id="footer" class="panel">
  <div class="panel-footer">
	<div class="container-fluid">
	  <div class="row">
		<div class="col-sm-5">

		  <p>&copy 2022 Siddhant Bansal. Site made with <a href="https://jekyllrb.com">Jekyll</a>.</p>
		   <p>  </p><p>


		</div>
		<div class="col-sm-5">
		</div>
    <div class="col-sm-5">
		</div>
		<div class="col-sm-5">
		</div>
	  </div>
	</div>
  </div>
</div>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="http://localhost:4000/js/bootstrap.min.js"></script>


  </body>

</html>
