- title: 'My View is the Best View: Procedure Learning from Egocentric Videos'
  image: CVPR_diagrams-Correspondences_v1_2.png
  description: We propose the <b>EgoProceL dataset</b> consisting of 62 hours of videos captured by 130 subjects performing 16 tasks and a self-supervised <b>Correspond and Cut (CnC) framework</b> for procedure learning. CnC utilizes the temporal correspondences between the key-steps across multiple videos to learn the procedure.
  authors: <b>Siddhant Bansal</b>, <a href="https://www.cse.iitd.ac.in/~chetan/">Chetan Arora</a>, <a href="https://faculty.iiit.ac.in/~jawahar/index.html">C.V. Jawahar</a>
  venue: European Conference on Computer Vision (<b>ECCV</b>), 2022
  number_link: 4
  link1:
    url: https://arxiv.org/pdf/2207.10883
    display: Paper
  link3:
    url: https://sid2697.github.io/egoprocel/
    display: Project Page
  link2:
    url: https://sid2697.github.io/egoprocel/#download
    display: <b>Download the EgoProceL Dataset</b>
  link4:
    url: https://github.com/Sid2697/EgoProceL-egocentric-procedure-learning
    display: Code

- title: 'Ego4D: Around the World in 3,000 Hours of Egocentric Video'
  image: ego4d.png
  description: We offer 3,670 hours of daily-life activity video spanning hundreds of scenarios captured by 931 unique camera wearers from 74 worldwide locations and 9 different countries.<br>We present a host of new benchmark challenges centered around understanding the first-person visual experience in the past (querying an episodic memory), present (analyzing hand-object manipulation, audio-visual conversation, and social interactions), and future (forecasting activities).
  authors: <br>Kristen Grauman, Andrew Westbury, Eugene Byrne, Zachary Chavis, Antonino Furnari, Rohit Girdhar, Jackson Hamburger, Hao Jiang, Miao Liu, Xingyu Liu, Miguel Martin, Tushar Nagarajan, Ilija Radosavovic, Santhosh Kumar Ramakrishnan, Fiona Ryan, Jayant Sharma, Michael Wray, Mengmeng Xu, Eric Zhongcong Xu, Chen Zhao, <a href='https://sid2697.github.io/'><b>Siddhant Bansal</b></a>, Dhruv Batra, Vincent Cartillier, Sean Crane, Tien Do, Morrie Doulaty, Akshay Erapalli, Christoph Feichtenhofer, Adriano Fragomeni, Qichen Fu, Christian Fuegen, Abrham Gebreselasie, Cristina Gonzalez, James Hillis, Xuhua Huang, Yifei Huang, Wenqi Jia, Weslie Khoo, Jachym Kolar, Satwik Kottur, Anurag Kumar, Federico Landini, Chao Li, Yanghao Li, Zhenqiang Li, Karttikeya Mangalam, Raghava Modhugu, Jonathan Munro, Tullie Murrell, Takumi Nishiyasu, Will Price, Paola Ruiz Puentes, Merey Ramazanova, Leda Sari, Kiran Somasundaram, Audrey Southerland, Yusuke Sugano, Ruijie Tao, Minh Vo, Yuchen Wang, Xindi Wu, Takuma Yagi, Yunyi Zhu, Pablo Arbelaez, David Crandall, Dima Damen, Giovanni Maria Farinella, Bernard Ghanem, Vamsi Krishna Ithapu, C. V. Jawahar, Hanbyul Joo, Kris Kitani, Haizhou Li, Richard Newcombe, Aude Oliva, Hyun Soo Park, James M. Rehg, Yoichi Sato, Jianbo Shi, Mike Zheng Shou, Antonio Torralba, Lorenzo Torresani, Mingfei Yan, Jitendra Malik
  venue: Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022 <span style="color:red;">(ORAL)</span>
  number_link: 5
  link1:
    url: https://arxiv.org/abs/2110.07058
    display: Paper
  link2:
    url: https://ego4d-data.org/
    display: Project Page
  link3:
    url: https://www.youtube.com/watch?v=taC2ZKl9IsE
    display: Video
  link4:
    url: https://drive.google.com/file/d/1oknfQIH9w1rXy6I1j5eUE6Cqh96UwZ4L/view
    display: Benchmark's description
  link5:
    url: https://eyewear-computing.org/EPIC_ICCV21/
    display: EPIC@ICCV2021 Ego4D Reveal Session

- title: Improving Word Recognition using Multiple Hypotheses and Deep Embeddings
  image: Confidence_module.png
  description: We propose to fuse recognition-based and recognition-free approaches for word recognition using learning-based methods.
  authors: <b>Siddhant Bansal</b>, <a href="https://kris314.github.io"> Praveen Krishnan </a>, and <a href="https://faculty.iiit.ac.in/~jawahar/index.html"> C.V. Jawahar </a>
  venue: International Conference on Pattern Recognition (<b>ICPR</b>), 2020
  number_link: 4
  link1:
    url: https://arxiv.org/pdf/2010.14411.pdf
    display: Paper
  link2:
    url: https://sid2697.github.io/embednet_cab/
    display: Project Page
  link3:
    url: https://github.com/Sid2697/Word-recognition-EmbedNet-CAB
    display: Code (GitHub)
  link4:
    url: https://youtu.be/T_TYL-_HpbY
    display: Video (YouTube)<br><br>

- title: Fused Text Recogniser and Deep  Embeddings Improve  Word  Recognition  and  Retrieval
  image: WordRecVisualisation_website.png
  description: Fusing recognition-based and recognition-free approaches using rule-based methods for improving word recognition and retrieval.
  authors: <b>Siddhant Bansal</b>, <a href="https://kris314.github.io"> Praveen Krishnan </a>, and <a href="https://faculty.iiit.ac.in/~jawahar/index.html"> C.V. Jawahar </a>
  venue: IAPR International Workshop on Document Analysis and System (<b>DAS</b>), 2020 <span style="color:red;">(ORAL)</span>
  number_link: 5
  link1:
    url: https://arxiv.org/pdf/2007.00166.pdf
    display: Paper
  link2:
    url: ../images/pubpic/Word_Retrieval_demo.gif
    display: Demo
  link3:
    url: https://sid2697.github.io/Word-recognition-and-retrieval/
    display: Project Page
  link4:
    url: https://github.com/Sid2697/Word-recognition-and-retrieval
    display: Code (Github)
  link5:
    url: ../papers/Siddhant_Bansal_V4.pdf
    display: Poster
